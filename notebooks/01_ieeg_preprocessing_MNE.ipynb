{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dce6adc",
   "metadata": {},
   "source": [
    "# Preprocessing intracranial EEG using MNE-python\n",
    "\n",
    "\n",
    "*WIRED 2024*  \n",
    "[Maansi Desai, PhD](https://maansidesai.github.io/)  \n",
    "Postdoctoral Researcher in the [Hamilton Lab](https://slhs.utexas.edu/research/hamilton-lab)\n",
    "<br>\n",
    "Department of Speech, Language, and Hearing Sciences \n",
    "<br>\n",
    "The University of Texas at Austin \n",
    "\n",
    "## Part 1: Loading, Plotting, and Referencing\n",
    "This notebook will show you how to preprocess intracranial EEG using MNE-python. This uses an iEEG dataset on sentence listening which can be accessed [here](https://openneuro.org/datasets/ds003688/versions/1.0.7/metadata). This notebook covers the basics of how to look at iEEG data, interpret effects of referencing, and inspect data quality. In part 2, we will cover high gamma extraction and referencing. The method of high gamma extraction is identical to that used in [Hamilton et al. 2018](https://doi.org/10.1016/j.cub.2018.04.033) and [Hamilton et al. 2021](https://doi.org/10.1016/j.cell.2021.07.019).\n",
    "\n",
    "## Python libraries used in this tutorial\n",
    "\n",
    "* matplotlib\n",
    "* mne_bids\n",
    "* [MNE-python](https://mne.tools/stable/install/index.html)\n",
    "* numpy\n",
    "* pandas\n",
    "* pybids\n",
    "\n",
    "## What you will do in this tutorial\n",
    "\n",
    "* Load an iEEG dataset in MNE-python\n",
    "* Plot the power spectrum of the data to check for bad channels and compare channel types\n",
    "* Re-reference the data according to different reference schemes\n",
    "* Based on the functions and tools you will learn, there will be some portions throughout the tutorial where we will ask you to test out your knowledge in areas of the notebook which say `Try on your own` \n",
    "\n",
    "### part 2! ([`02_ieeg_preprocessing_MNE_epochs.ipynb`](02_ieeg_preprocessing_MNE_epochs.ipynb))\n",
    "* Compute the high gamma analytic amplitude of the signal\n",
    "* Plot evoked data\n",
    "\n",
    "### part 3! ([`03_plot_electrodes.ipynb`](03_plot_electrodes.ipynb)) -- visualization tools [optional]\n",
    "* load electrode coordinates stored in imaging from BIDS data and plot location on the brain for visualization purposes\n",
    "* This notebook will mostly be a resource to show you how to plot electrodes on the brain and will also allow you to plot evoked responses on the brain as well. \n",
    "* We will not be going over this notebook during this workshop, however we encourage you to take a look at this code on your own time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e3af5",
   "metadata": {},
   "source": [
    "# A high-level summary for preprocessing intracranial data\n",
    "\n",
    "### Frequency Bands\n",
    "\n",
    "EEG records neural responses best in the range of 1-25Hz. However, ECoG can record from a much higher range of frequency, up into gamma and high gamma (70-150Hz) bands. This is especially exciting for speech researchers, because high-gamma band activity has been correlated with a lot of speech stimuli!\n",
    "\n",
    "However, to extract high gamma response we need to do something called a Hilbert transform. We'll talk more about that in `02_ieeg_preprocessing_MNE_epochs` notebook. \n",
    "\n",
    "### Artifacts\n",
    "\n",
    "ECoG is invasive, that is, it's placed directly on the surface of the brain (or in the brain, in the case of depth electrodes). Some of the artifacts we may encounter are related to the patient's epilepsy or other movement-related noise. We'll go over examples of what these artifacts look like. \n",
    "\n",
    "### Referencing\n",
    "\n",
    "There are different methods that people use for rereferencing intracranial data. For sEEG/ECoG instead we use a common average reference (CAR), which means we are referencing based on the average activity at all electrodes. But we will go over a couple of rereferencing methods and will plot the neural data to give you an idea of how the data look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb884ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib notebook\n",
    "#%matplotlib tk\n",
    "\n",
    "import mne\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from mne_bids import read_raw_bids, print_dir_tree\n",
    "from mne_bids.path import get_bids_path_from_fname\n",
    "from bids import BIDSLayout\n",
    "from ecog_preproc_utils import transformData\n",
    "import bids\n",
    "import re  # regex for comparing channel names\n",
    "\n",
    "print(mne.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f2b5d",
   "metadata": {},
   "source": [
    "## Download BIDS iEEG dataset\n",
    "\n",
    "Here we will download an example iEEG dataset from some [pediatric intracranial data collected from the Hamilton Lab](https://openneuro.org/datasets/ds004993/versions/1.0.2). \n",
    "\n",
    "For this tutorial we will use data from: \n",
    " - `sub-W1`, `iemu` data only, for detecting seizure activity. \n",
    " - `sub-W2`, `iemu` data only, for epoching data to the onset of the speech stimuli (from the [TIMIT speech corpus](https://catalog.ldc.upenn.edu/LDC93S1)) and plotting the evoked responses in the `02_ieeg_preprocessing_MNE_epochs` notebook. \n",
    " - `sub-W3`, `iemu` data only, for detecting artifacts from a vagus nerve stimulator (VNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3661b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the example participant's data that we will load for the tutorial,\n",
    "# but there are more options.\n",
    "subj = 'W2'\n",
    "sess = 'iemu'\n",
    "task = 'timit5'\n",
    "acq = 'B8'\n",
    "run = '01'\n",
    "\n",
    "# Change the data directory below to where your data are located. \n",
    "parent_dir = 'data/ds004993'  # This is on your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2655a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_ieeg.edf\n"
     ]
    }
   ],
   "source": [
    "ieeg_dir = f'{parent_dir}/sub-{subj}/ses-{sess}/ieeg/'\n",
    "channel_path = f'{ieeg_dir}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_channels.tsv'\n",
    "raw_path = f'{ieeg_dir}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_ieeg.edf'\n",
    "\n",
    "\n",
    "bids_path = get_bids_path_from_fname(raw_path)\n",
    "base_name = os.path.basename(raw_path).split('.')[0]\n",
    "\n",
    "print(bids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135875c5",
   "metadata": {},
   "source": [
    "**Remark:** Note that bids_path is an instance of [BIDSPath](https://mne.tools/mne-bids/dev/generated/mne_bids.BIDSPath.html) object in mne_bids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17673c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIDSPath(\n",
       "root: data/ds004993\n",
       "datatype: ieeg\n",
       "basename: sub-W2_ses-iemu_task-timit5_acq-B8_run-01_ieeg.edf)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97922f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('W2', 'iemu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_path.subject, bids_path.session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9faf41",
   "metadata": {},
   "source": [
    "## BIDS layout\n",
    "\n",
    "We can use `pybids` to show a little bit about the files in this BIDS dataset. We won't get as much into this, but if you'd like to try this tutorial on your own you may wish to delve into this more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953df68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d328249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movietrailers', 'timit5', 'timit4']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cb681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 files in the layout.\n",
      "\n",
      "The first 10 files are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<BIDSFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/CHANGES'>,\n",
       " <BIDSJSONFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/dataset_description.json'>,\n",
       " <BIDSJSONFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/participants.json'>,\n",
       " <BIDSDataFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/participants.tsv'>,\n",
       " <BIDSFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/README'>,\n",
       " <BIDSDataFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/sub-W1/ses-iemu/ieeg/sub-W1_ses-iemu_task-movietrailers_acq-B3_run-01_channels.tsv'>,\n",
       " <BIDSJSONFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/sub-W1/ses-iemu/ieeg/sub-W1_ses-iemu_task-movietrailers_acq-B3_run-01_coordsystem.json'>,\n",
       " <BIDSDataFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/sub-W1/ses-iemu/ieeg/sub-W1_ses-iemu_task-movietrailers_acq-B3_run-01_electrodes.tsv'>,\n",
       " <BIDSDataFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/sub-W1/ses-iemu/ieeg/sub-W1_ses-iemu_task-movietrailers_acq-B3_run-01_events.tsv'>,\n",
       " <BIDSFile filename='/Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/sub-W1/ses-iemu/ieeg/sub-W1_ses-iemu_task-movietrailers_acq-B3_run-01_ieeg.edf'>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = layout.get()\n",
    "print(\"There are {} files in the layout.\".format(len(all_files)))\n",
    "print(\"\\nThe first 10 files are:\")\n",
    "all_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0587e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|ds004993/\n",
      "|--- .DS_Store\n",
      "|--- .bidsignore\n",
      "|--- CHANGES\n",
      "|--- README\n",
      "|--- dataset_description.json\n",
      "|--- participants.json\n",
      "|--- participants.tsv\n",
      "|--- freesurfer/\n",
      "|------ .DS_Store\n",
      "|------ sub-W1/\n",
      "|--------- W1_lateral_lh.png\n",
      "|--------- W1_lateral_rh.png\n",
      "|--------- W1_ventral.png\n",
      "|--------- bem/\n",
      "|--------- surf/\n",
      "|------ sub-W2/\n",
      "|--------- W2_lateral_rh.png\n",
      "|--------- W2_ventral_rh.png\n",
      "|--------- bem/\n",
      "|--------- surf/\n",
      "|------ sub-W3/\n",
      "|--------- .DS_Store\n",
      "|--------- W3_frontal.png\n",
      "|--------- W3_lateral_lh.png\n",
      "|--------- W3_lateral_rh.png\n",
      "|--------- bem/\n",
      "|--------- surf/\n",
      "|--- sub-W1/\n",
      "|------ ses-iemu/\n",
      "|--------- sub-W1_ses-iemu_scans.tsv\n",
      "|--------- ieeg/\n",
      "|------ ses-mri/\n",
      "|--------- anat/\n",
      "|--- sub-W2/\n",
      "|------ ses-iemu/\n",
      "|--------- sub-W2_ses-iemu_scans.tsv\n",
      "|--------- ieeg/\n",
      "|------ ses-mri/\n",
      "|--------- anat/\n",
      "|--- sub-W3/\n",
      "|------ ses-iemu/\n",
      "|--------- sub-W3_ses-iemu_scans.tsv\n",
      "|--------- ieeg/\n",
      "|------ ses-mri/\n",
      "|--------- anat/\n"
     ]
    }
   ],
   "source": [
    "print_dir_tree(parent_dir, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da51ef",
   "metadata": {},
   "source": [
    "## Let's load some iEEG data!\n",
    "\n",
    "First, we will choose the relevant subject, session, task, acquisition, and run. Note that if you wish to change these variables, you may need to download the data yourself.\n",
    "\n",
    "To show the capabilities of BIDS and contrast to when we don't use BIDS, we'll load the data in two ways. The data structure using BIDS will be called `raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4431118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_ieeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading events from data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_events.tsv.\n",
      "Reading channel info from data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_channels.tsv.\n",
      "Reading electrode coords from data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_electrodes.tsv.\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/nrm13jr11b734k78bp62stg80000gq/T/ipykernel_55590/4023317972.py:2: RuntimeWarning: Omitted 102 annotation(s) that were outside data range.\n",
      "  raw = read_raw_bids(bids_path, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "# Read data and extract parameters from BIDS files\n",
    "raw = read_raw_bids(bids_path, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f183f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 182783  =      0.000 ...   356.998 secs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>January 01, 2024  00:00:00 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>mne_anonymize</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            \n",
       "            <td>sub-W2</td>\n",
       "            \n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>106 points</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>106 sEEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>512.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>256.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<Info | 12 non-empty values\n",
       " bads: []\n",
       " ch_names: RAST1, RAST2, RAST3, RAST4, RAST5, RAST6, RAST7, RAST8, RAST9, ...\n",
       " chs: 106 sEEG\n",
       " custom_ref_applied: False\n",
       " description: Anonymized using a time shift to preserve age at acquisition\n",
       " dig: 106 items (106 EEG)\n",
       " experimenter: mne_anonymize\n",
       " highpass: 0.0 Hz\n",
       " line_freq: 60.0\n",
       " lowpass: 256.0 Hz\n",
       " meas_date: 2024-01-01 00:00:00 UTC\n",
       " nchan: 106\n",
       " projs: []\n",
       " sfreq: 512.0 Hz\n",
       " subject_info: 4 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load the data into memory and print some information about it. The \n",
    "# info structure contains a lot of helpful metadata about number of channels,\n",
    "# sampling rate, data types, etc. It can also contain information about the\n",
    "# participant and date of acquisition, however, this dataset has been anonymized.\n",
    "raw.load_data()\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12cad9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RAST1',\n",
       " 'RAST2',\n",
       " 'RAST3',\n",
       " 'RAST4',\n",
       " 'RAST5',\n",
       " 'RAST6',\n",
       " 'RAST7',\n",
       " 'RAST8',\n",
       " 'RAST9',\n",
       " 'RAST10',\n",
       " 'RAST11',\n",
       " 'RAST12',\n",
       " 'RMST1',\n",
       " 'RMST2',\n",
       " 'RMST3',\n",
       " 'RMST4',\n",
       " 'RMST5',\n",
       " 'RMST6',\n",
       " 'RMST7',\n",
       " 'RMST8',\n",
       " 'RMST9',\n",
       " 'RMST10',\n",
       " 'RMST11',\n",
       " 'RMST12',\n",
       " 'RMST13',\n",
       " 'RMST14',\n",
       " 'RPST1',\n",
       " 'RPST2',\n",
       " 'RPST3',\n",
       " 'RPST4',\n",
       " 'RPST5',\n",
       " 'RPST6',\n",
       " 'RPST7',\n",
       " 'RPST8',\n",
       " 'RPST9',\n",
       " 'RPST10',\n",
       " 'RPST11',\n",
       " 'RPST12',\n",
       " 'RPPST1',\n",
       " 'RPPST2',\n",
       " 'RPPST3',\n",
       " 'RPPST4',\n",
       " 'RPPST5',\n",
       " 'RPPST6',\n",
       " 'RPPST7',\n",
       " 'RPPST8',\n",
       " 'RPPST9',\n",
       " 'RPPST10',\n",
       " 'RPPST11',\n",
       " 'RPPST12',\n",
       " 'RPPST13',\n",
       " 'RPPST14',\n",
       " 'RPPST15',\n",
       " 'RPPST16',\n",
       " 'RAIF1',\n",
       " 'RAIF2',\n",
       " 'RAIF3',\n",
       " 'RAIF4',\n",
       " 'RAIF5',\n",
       " 'RAIF6',\n",
       " 'RAIF7',\n",
       " 'RAIF8',\n",
       " 'RPI1',\n",
       " 'RPI2',\n",
       " 'RPI3',\n",
       " 'RPI4',\n",
       " 'RPI5',\n",
       " 'RPI6',\n",
       " 'RPI7',\n",
       " 'RPI8',\n",
       " 'RPI9',\n",
       " 'RPI10',\n",
       " 'RPI11',\n",
       " 'RPI12',\n",
       " 'RPI13',\n",
       " 'RPI14',\n",
       " 'RPI15',\n",
       " 'RPI16',\n",
       " 'ROF1',\n",
       " 'ROF2',\n",
       " 'ROF3',\n",
       " 'ROF4',\n",
       " 'ROF5',\n",
       " 'ROF6',\n",
       " 'ROF7',\n",
       " 'ROF8',\n",
       " 'ROF9',\n",
       " 'ROF10',\n",
       " 'ROF11',\n",
       " 'ROF12',\n",
       " 'ROF13',\n",
       " 'ROF14',\n",
       " 'ROF15',\n",
       " 'ROF16',\n",
       " 'RAC1',\n",
       " 'RAC2',\n",
       " 'RAC3',\n",
       " 'RAC4',\n",
       " 'RAC5',\n",
       " 'RAC6',\n",
       " 'RAC7',\n",
       " 'RAC8',\n",
       " 'RAC9',\n",
       " 'RAC10',\n",
       " 'RAC11',\n",
       " 'RAC12']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['ch_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb13c7",
   "metadata": {},
   "source": [
    "## Plot the raw data\n",
    "\n",
    "Let's first inspect the raw data to see how it looks, what type of information we have, and whether we can immediately see any bad channels or bad time segments that should be rejected. Typically this portion should be done interactively so you can scroll through the data using the arrow keys. \n",
    "\n",
    "Compare and contrast the data loaded using mne-bids (`raw`) versus the data loaded without this information.\n",
    "To get a raw object using mne-bids you can use the `read_raw_bids` function. See 2 cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8ebbcf7-e6c1-48b7-988a-4ae59240c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using qt as 2D backend.\n",
      "Using pyopengl with version 3.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.openglcontext: Could not find virtual screen for QCocoaScreen(0x7f99d8c64210, \"\", QRect(-1920,0 1920x1080), dpr=1, displayId=4128833, <NSScreen: 0x7f99d8c61080>) with displayId 4128833\n",
      "qt.qpa.openglcontext: Could not find virtual screen for QCocoaScreen(0x7f99d8c64210, \"\", QRect(-1920,0 1920x1080), dpr=1, displayId=4128833, <NSScreen: 0x7f99d8c61080>) with displayId 4128833\n",
      "qt.qpa.openglcontext: Could not find virtual screen for QCocoaScreen(0x7f99d8c64210, \"\", QRect(-1920,0 1920x1080), dpr=1, displayId=4128833, <NSScreen: 0x7f99d8c61080>) with displayId 4128833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "# mne.viz.set_browser_backend('matplotlib')\n",
    "raw.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273603c",
   "metadata": {},
   "source": [
    "**NOTE:** From now on we will be using the mne-bids version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7eacff-281c-4cea-81d6-ab40ce9e5b4c",
   "metadata": {},
   "source": [
    "## Plot the power spectrum\n",
    "\n",
    "Now we will plot the power spectrum of the signal to give us an idea of the signals we're getting. Bad channels (or channels that are not EEG/ECoG) will often have a very different power spectrum than the good channels. These will show up as highly outside the range of the other channels (either flat, or much higher/lower power)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8af76e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/maansidesai/Desktop/git/WIRED-2024-Paris/notebooks/data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_ieeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading events from data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_events.tsv.\n",
      "Reading channel info from data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_channels.tsv.\n",
      "Reading electrode coords from data/ds004993/sub-W2/ses-iemu/ieeg/sub-W2_ses-iemu_task-timit5_acq-B8_run-01_electrodes.tsv.\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Reading 0 ... 182783  =      0.000 ...   356.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/nrm13jr11b734k78bp62stg80000gq/T/ipykernel_55590/3090690490.py:1: RuntimeWarning: Omitted 102 annotation(s) that were outside data range.\n",
      "  raw = read_raw_bids(bids_path, verbose=True)  # let's reload so we are sure to all use the BIDS version.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>January 01, 2024  00:00:00 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>mne_anonymize</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            \n",
       "            <td>sub-W2</td>\n",
       "            \n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>106 points</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>106 sEEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>512.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>256.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Filenames</th>\n",
       "                    <td>sub-W2_ses-iemu_task-timit5_acq-B8_run-01_ieeg.edf</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Duration</th>\n",
       "                    <td>00:05:57 (HH:MM:SS)</td>\n",
       "                </tr>\n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<RawEDF | sub-W2_ses-iemu_task-timit5_acq-B8_run-01_ieeg.edf, 106 x 182784 (357.0 s), ~147.9 MB, data loaded>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_raw_bids(bids_path, verbose=True)  # let's reload so we are sure to all use the BIDS version.\n",
    "raw.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc514b6-ed0e-4e69-99ff-8fe3bc4e4476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 4.000 (s)\n"
     ]
    }
   ],
   "source": [
    "raw.compute_psd().plot(picks='data', exclude=[]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "798d3c6d-4669-4ddd-9fcc-12620b5cd473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_psd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'welch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpicks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mproj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mremove_dc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreject_by_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mmethod_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Perform spectral analysis on sensor data.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "\n",
       "method : ``'welch'`` | ``'multitaper'``\n",
       "    Spectral estimation method. ``'welch'`` uses Welch's\n",
       "    method :footcite:p:`Welch1967`, ``'multitaper'`` uses DPSS\n",
       "    tapers :footcite:p:`Slepian1978`.\n",
       "    Default is ``'welch'``.\n",
       "fmin, fmax : float\n",
       "    The lower- and upper-bound on frequencies of interest. Default is ``fmin=0, fmax=np.inf`` (spans all frequencies present in the data).\n",
       "tmin, tmax : float | None\n",
       "    First and last times to include, in seconds. ``None`` uses the first or\n",
       "    last time present in the data. Default is ``tmin=None, tmax=None`` (all\n",
       "    times).\n",
       "picks : str | array-like | slice | None\n",
       "    Channels to include. Slices and lists of integers will be interpreted as \n",
       "    channel indices. In lists, channel *type* strings (e.g., ``['meg', \n",
       "    'eeg']``) will pick channels of those types, channel *name* strings (e.g., \n",
       "    ``['MEG0111', 'MEG2623']`` will pick the given channels. Can also be the \n",
       "    string values \"all\" to pick all channels, or \"data\" to pick :term:`data \n",
       "    channels`. None (default) will pick good data channels (excluding reference \n",
       "    MEG channels). Note that channels in ``info['bads']`` *will be included* if \n",
       "    their names or indices are explicitly provided.\n",
       "exclude : list of str | 'bads'\n",
       "    Channel names to exclude. If ``'bads'``, channels\n",
       "    in ``info['bads']`` are excluded; pass an empty list to\n",
       "    include all channels (including \"bad\" channels, if any).\n",
       "proj : bool\n",
       "    Whether to apply SSP projection vectors before spectral estimation.\n",
       "    Default is ``False``.\n",
       "\n",
       "remove_dc : bool\n",
       "    If ``True``, the mean is subtracted from each segment before computing\n",
       "    its spectrum.\n",
       "reject_by_annotation : bool\n",
       "    Whether to omit bad spans of data before spectral estimation. If\n",
       "    ``True``, spans with annotations whose description begins with\n",
       "    ``bad`` will be omitted.\n",
       "n_jobs : int | None\n",
       "    The number of jobs to run in parallel. If ``-1``, it is set\n",
       "    to the number of CPU cores. Requires the :mod:`joblib` package.\n",
       "    ``None`` (default) is a marker for 'unset' that will be interpreted\n",
       "    as ``n_jobs=1`` (sequential execution) unless the call is performed under\n",
       "    a :class:`joblib:joblib.parallel_config` context manager that sets another\n",
       "    value for ``n_jobs``.\n",
       "\n",
       "verbose : bool | str | int | None\n",
       "    Control verbosity of the logging output. If ``None``, use the default\n",
       "    verbosity level. See the :ref:`logging documentation <tut-logging>` and\n",
       "    :func:`mne.verbose` for details. Should only be passed as a keyword\n",
       "    argument.\n",
       "**method_kw\n",
       "    Additional keyword arguments passed to the spectral estimation\n",
       "    function (e.g., ``n_fft, n_overlap, n_per_seg, average, window``\n",
       "    for Welch method, or\n",
       "    ``bandwidth, adaptive, low_bias, normalization`` for multitaper\n",
       "    method). See :func:`~mne.time_frequency.psd_array_welch` and\n",
       "    :func:`~mne.time_frequency.psd_array_multitaper` for details.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "spectrum : instance of Spectrum\n",
       "    The spectral representation of the data.\n",
       "\n",
       "Notes\n",
       "-----\n",
       ".. versionadded:: 1.2\n",
       "\n",
       "References\n",
       "----------\n",
       ".. footbibliography::\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Applications/MNE-Python/1.6.1_0/.mne-python/lib/python3.11/site-packages/mne/io/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If we want to see other options we have for computing the power spectrum, \n",
    "# we can consult the help function\n",
    "raw.compute_psd?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c552534-385a-4d72-830a-25219205c3e9",
   "metadata": {},
   "source": [
    "## Referencing\n",
    "\n",
    "Referencing or re-referencing your data should be done with some knowledge of your recording setup and what you wish to measure. You can read more about referencing [here (for EEG)](https://pressrelease.brainproducts.com/referencing/#:~:text=The%20reference%20influences%20the%20amplitude,affected%20by%20similar%20electrical%20activity.). Typically, experimenters will choose one of the following references:\n",
    "\n",
    "1. Based on a single electrode in white matter (or relatively \"quiet\" electrode far away from your signals of interest).\n",
    "2. Based on the average of all electrodes or a block of electrodes (CAR or Common Average Reference). Note that the CAR is *not* a good idea if all of your electrodes are within a single functional area, as you will likely subtract out more signal than noise. \n",
    "3. Bipolar referencing, in which pairs of adjacent electrodes are subtracted to calculate more local signals. This is a bit more complicated but allows you to work with data in a single region without the drawbacks of the CAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6819b3ae-74b3-4b15-82bd-3a1317c9a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sEEG channel type selected for re-referencing\n",
      "Applying a custom ('sEEG',) reference.\n",
      "Using pyopengl with version 3.1.6\n"
     ]
    }
   ],
   "source": [
    "# Example of single reference channel - this subtracts the signal from this channel\n",
    "# from all other channels (including itself), so the reference will appear as a flat\n",
    "# line after this step\n",
    "raw_ref = raw.copy()\n",
    "raw_ref.set_eeg_reference(ref_channels = ['RAC12'], ) #Here we are just picking a channel that looks relatively noise-free \n",
    "raw_ref.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a168a192-0955-4f60-8269-6967d284e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sEEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('sEEG',) reference.\n",
      "Using pyopengl with version 3.1.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x1b9921510>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of common average reference. The common average reference subtracts the average\n",
    "# signal across all *good* channels from every single channel. This is typically a good\n",
    "# choice for removing noise across all channels (for example, sometimes EMG from chewing,\n",
    "# some movement artifacts, electrical noise).\n",
    "raw_ref_car = raw.copy()\n",
    "raw_ref_car.set_eeg_reference(ref_channels = 'average')\n",
    "raw_ref_car.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d2261-53ab-4dca-b9c6-7431b6f5b369",
   "metadata": {},
   "source": [
    "## Bipolar reference\n",
    "\n",
    "Bipolar referencing is a bit trickier and is not fully implemented here. You need to use knowledge of the physical locations of the electrodes to properly create the bipolar montage. For example, in the image below, we would need to use the knowledge of how the electrodes are placed in order to create the appropriate pairs for the anode and cathode.\n",
    "\n",
    "![sub-06 electrode locations](sub-06_ses-iemu_acq-render_photo_ecog_left.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b93fe3c-905c-4569-8da1-081a5559c91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sEEG channel type selected for re-referencing\n",
      "Creating RawArray with float64 data, n_channels=98, n_times=182784\n",
      "    Range : 0 ... 182783 =      0.000 ...   356.998 secs\n",
      "Ready.\n",
      "Added the following bipolar channels:\n",
      "RAST1-RAST2, RAST2-RAST3, RAST3-RAST4, RAST4-RAST5, RAST5-RAST6, RAST6-RAST7, RAST7-RAST8, RAST8-RAST9, RAST9-RAST10, RAST10-RAST11, RAST11-RAST12, RMST1-RMST2, RMST2-RMST3, RMST3-RMST4, RMST4-RMST5, RMST5-RMST6, RMST6-RMST7, RMST7-RMST8, RMST8-RMST9, RMST9-RMST10, RMST10-RMST11, RMST11-RMST12, RMST12-RMST13, RMST13-RMST14, RPST1-RPST2, RPST2-RPST3, RPST3-RPST4, RPST4-RPST5, RPST5-RPST6, RPST6-RPST7, RPST7-RPST8, RPST8-RPST9, RPST9-RPST10, RPST10-RPST11, RPST11-RPST12, RPPST1-RPPST2, RPPST2-RPPST3, RPPST3-RPPST4, RPPST4-RPPST5, RPPST5-RPPST6, RPPST6-RPPST7, RPPST7-RPPST8, RPPST8-RPPST9, RPPST9-RPPST10, RPPST10-RPPST11, RPPST11-RPPST12, RPPST12-RPPST13, RPPST13-RPPST14, RPPST14-RPPST15, RPPST15-RPPST16, RAIF1-RAIF2, RAIF2-RAIF3, RAIF3-RAIF4, RAIF4-RAIF5, RAIF5-RAIF6, RAIF6-RAIF7, RAIF7-RAIF8, RPI1-RPI2, RPI2-RPI3, RPI3-RPI4, RPI4-RPI5, RPI5-RPI6, RPI6-RPI7, RPI7-RPI8, RPI8-RPI9, RPI9-RPI10, RPI10-RPI11, RPI11-RPI12, RPI12-RPI13, RPI13-RPI14, RPI14-RPI15, RPI15-RPI16, ROF1-ROF2, ROF2-ROF3, ROF3-ROF4, ROF4-ROF5, ROF5-ROF6, ROF6-ROF7, ROF7-ROF8, ROF8-ROF9, ROF9-ROF10, ROF10-ROF11, ROF11-ROF12, ROF12-ROF13, ROF13-ROF14, ROF14-ROF15, ROF15-ROF16, RAC1-RAC2, RAC2-RAC3, RAC3-RAC4, RAC4-RAC5, RAC5-RAC6, RAC6-RAC7, RAC7-RAC8, RAC8-RAC9, RAC9-RAC10, RAC10-RAC11, RAC11-RAC12\n",
      "Using pyopengl with version 3.1.6\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "# Example of bipolar reference. This would normally be done with some manual\n",
    "# intervention of the specific channel pairs. \n",
    "raw_ieeg = raw.copy()\n",
    "# raw_ieeg.pick_types(eeg=True)\n",
    "ch_pairs = list(zip(raw_ieeg.info['ch_names'][:-1],\n",
    "                    raw_ieeg.info['ch_names'][1:]))\n",
    "\n",
    "# Make a list of channels for the anode and the cathode\n",
    "anode = []\n",
    "cathode = []\n",
    "# Only subtract channels with the same device name (these will be\n",
    "# close in space). This is still not ideal as we are probably\n",
    "# subtracting electrodes that are far away from one another in \n",
    "# space (for example, electrodes 8 and 9 on the grid picture\n",
    "# above should not be used for a bipolar reference)\n",
    "for pair in ch_pairs:\n",
    "    # get rid of the numbers in the ch_name\n",
    "    ch1_dev = re.sub(r'\\d+', '', pair[0]) \n",
    "    ch2_dev = re.sub(r'\\d+', '', pair[1]) \n",
    "    # if these are part of the same device, consider them for \n",
    "    # anode and cathode selection\n",
    "    if ch1_dev == ch2_dev:\n",
    "        anode.append(pair[0])\n",
    "        cathode.append(pair[1])\n",
    "\n",
    "# Apply the bipolar reference\n",
    "raw_ref_bip = mne.set_bipolar_reference(raw, anode=anode, cathode=cathode)\n",
    "raw_ref_bip.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d048c-f4c1-4a1c-9f80-2bf4906724d3",
   "metadata": {},
   "source": [
    "# Now let's look at other types of artifacts that you may encounter while preprocessing intracranial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb7a55f7-60e3-43a9-8a54-61257979b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ds004993/sub-W1/ses-iemu/ieeg/sub-W1_ses-iemu_task-movietrailers_acq-B3_run-01_ieeg.edf\n",
      "I ran \"black\" formatting on the .py files\n"
     ]
    }
   ],
   "source": [
    "# We're going to start by loading another patient from our BIDS data\n",
    "\n",
    "subj = 'W1'\n",
    "sess = 'iemu'\n",
    "task = 'movietrailers'\n",
    "acq = 'B3'\n",
    "run = '01'\n",
    "\n",
    "# Change the data directory below to where your data are located. \n",
    "parent_dir = 'data/ds004993'  # This is on your local machine\n",
    "\n",
    "ieeg_dir_epi = f'{parent_dir}/sub-{subj}/ses-{sess}/ieeg/'\n",
    "channel_path_epi = f'{ieeg_dir_epi}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_channels.tsv'\n",
    "raw_path_epi = f'{ieeg_dir_epi}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_ieeg.edf'\n",
    "\n",
    "bids_path_epi = get_bids_path_from_fname(raw_path_epi)\n",
    "base_name_epi = os.path.basename(raw_path_epi).split('.')[0]\n",
    "\n",
    "print(bids_path_epi)\n",
    "print('I ran \"black\" formatting on the .py files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e83c5b-adc3-4815-8c23-2b11a6a5b8ff",
   "metadata": {},
   "source": [
    "## This specific block of data will show what seizure activity looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d13fd",
   "metadata": {},
   "source": [
    "#### Try on your own: Take a moment and try to plot the raw data on your own. \n",
    "\n",
    "Hint: Use `bids_path_epi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dcaa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data, reject bad segments. Look for times where there\n",
    "# are spike wave discharges (epileptiform artifacts) or large\n",
    "# movement artifacts. Be selective, look out for blocks with a \n",
    "# ton of seizure activity\n",
    "\n",
    "### YOUR CODE HERE ### (bids_path_epi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b30ea3-dbdb-45d9-b561-3f73a2bf1ce5",
   "metadata": {},
   "source": [
    "## Epileptiform activity\n",
    "\n",
    "This is an example in one patient who is having a seizuring during one of our tasks. From this picture and the data you were able to scroll through above, you can see that there is a cyclical pattern of noise that is across all channels. In these cases,  you would not reject these channels only. Instead, you unfortunately would have to eliminate this particular recording block from your analysis. \n",
    "\n",
    "![epileptic artifact](epileptic_artifact.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a109679-1b4d-4cf8-b391-a8bcf1cfbbdb",
   "metadata": {},
   "source": [
    "## Vagus Nerve stimulator (VNS) artifact \n",
    "\n",
    "When working with intractable epilepsy patients, one of the factors that may create artifacts can arise from a [VNS device](https://www.epilepsy.com/treatment/devices/vagus-nerve-stimulation-therapy). In short, a VNS is a type of neuromodulation that delivers stimulation to the brain to specific parts of the brain that may cause epilepsy. Not all patients have a VNS, but you are working with a patient who does, we have found that there can be 20 Hz noise that appears when collecting data in the EMU. Let's take a look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8173c639-74ba-46c3-91d4-e693e36df37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ds004993\n",
      "data/ds004993/sub-W3/ses-iemu/ieeg//sub-W3_ses-iemu_task-timit4_acq-B8_run-01_ieeg.edf\n",
      "sub-W3_ses-iemu_task-timit4_acq-B8_run-01_ieeg\n"
     ]
    }
   ],
   "source": [
    "#We are going to load another patient's data that is stored in our BIDS dataset.  \n",
    "\n",
    "subj = 'W3'\n",
    "sess = 'iemu'\n",
    "task = 'timit4'\n",
    "acq = 'B8'\n",
    "run = '01'\n",
    "parent_dir = 'data/ds004993'  # This is on your local machine\n",
    "\n",
    "print(parent_dir)\n",
    "ieeg_dir_vns = f'{parent_dir}/sub-{subj}/ses-{sess}/ieeg/'\n",
    "channel_path_vns = f'{ieeg_dir_vns}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_channels.tsv'\n",
    "raw_path_vns = f'{ieeg_dir_vns}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_ieeg.edf'\n",
    "\n",
    "\n",
    "bids_path_vns = get_bids_path_from_fname(raw_path_vns)\n",
    "base_name_vns = os.path.basename(raw_path_vns).split('.')[0]\n",
    "\n",
    "print(raw_path_vns)\n",
    "print(base_name_vns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342846d",
   "metadata": {},
   "source": [
    "#### Try on your own:  Once again, take a moment and try to plot the raw data on your own. \n",
    "\n",
    "Hint: Use `bids_path_vns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a290839d-95b8-4352-a27f-c9984ca0bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data, to view VNS artifact\n",
    "\n",
    "### YOUR CODE HERE ### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e597ff-ffcd-4627-9488-441f99f64bd6",
   "metadata": {},
   "source": [
    "## VNS electrical activity\n",
    "\n",
    "This is an example in one patient that has electrical artifact from their VNS system\n",
    "\n",
    "![VNS artifact](vns_artifact.jpeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "957cd383-83a9-4e24-8cdb-1bd2e534c756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.000 (s)\n"
     ]
    }
   ],
   "source": [
    "raw_vns.compute_psd().plot(picks='data', exclude=[]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247dcbb7-2dd8-4106-beb4-e048cfc1ea26",
   "metadata": {},
   "source": [
    "## VNS power spectrum\n",
    "\n",
    "When we plot the power spectrum, we see consistent 20 Hz noise which is from the VNS neurostimulator. \n",
    "\n",
    "![VNS power spectrum](vns_power_spectrum.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc30cebe-6073-4edf-848a-cff899e225e5",
   "metadata": {},
   "source": [
    "## If you see electrical artifact from a VNS, such as this example, you don't need to reject every single time point when you plot the neural data for artifact rejection. Instead, performing referencing by using a common average reference (CAR) will help to eliminate this noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2ceab",
   "metadata": {},
   "source": [
    "#### Try on your own: Take a moment and try to plot the raw data on your own. \n",
    "\n",
    "Try to perform car on the `raw_vns` data. Then plot the data to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###   #perform a common average reference\n",
    "\n",
    "\n",
    "### YOUR CODE ###   # Plot the raw data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###   # Plot the raw data now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545256a0",
   "metadata": {},
   "source": [
    "## Want to plot some evoked data? \n",
    "\n",
    "Go to Part 2! [02_ieeg_preprocessing_MNE_epochs.ipynb](02_ieeg_preprocessing_MNE_epochs.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
