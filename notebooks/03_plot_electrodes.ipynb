{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dce6adc",
   "metadata": {},
   "source": [
    "# Preprocessing intracranial EEG using MNE-python\n",
    "\n",
    "\n",
    "*WIRED 2024*  \n",
    "[Maansi Desai, PhD](https://maansidesai.github.io/)  \n",
    "Postdoctoral Researcher in the [Hamilton Lab](https://slhs.utexas.edu/research/hamilton-lab)\n",
    "<br>\n",
    "Department of Speech, Language, and Hearing Sciences \n",
    "<br>\n",
    "The University of Texas at Austin \n",
    "\n",
    "## Part 3: Plotting electrodes on brain using MNE brain.viz function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb884ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import mne\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from mne_bids import read_raw_bids, print_dir_tree, BIDSPath\n",
    "from mne_bids.path import get_bids_path_from_fname\n",
    "from bids import BIDSLayout\n",
    "from ecog_preproc_utils import transformData\n",
    "import bids \n",
    "import re  # regex for comparing channel names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f2b5d",
   "metadata": {},
   "source": [
    "## Download BIDS iEEG dataset\n",
    "\n",
    "Here we will download an example iEEG dataset from [this dataset from the Hamilton lab](https://openneuro.org/datasets/ds004993/versions/1.1.1). If you have ran [`01_ieeg_preprocessing_MNE`](01_ieeg_preprocessing_MNE) and [`02_ieeg_preprocessing_MNE_epochs.ipynb`](02_ieeg_preprocessing_MNE_epochs.ipynb), then you should already have downloaded the necessary datasets locally. \n",
    "\n",
    "For this notebook we will use data from: \n",
    " - `sub-W1`, `iemu`, `B3`, `movietrailers`\n",
    " - `sub-W2`, `iemu`, `B8`, `timit5`\n",
    " - `sub-W3`, `iemu`, `B8`, `timit4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the example participant's data that we will load for the tutorial,\n",
    "# but there are more options.\n",
    "subj = 'W2'\n",
    "sess = 'iemu'\n",
    "task = 'timit5'\n",
    "acq = 'B8'\n",
    "run = '01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne_bids\n",
    "mne_bids.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data directory below to where your data are located. \n",
    "parent_dir = 'data/ds004993'  # This is on your local machine\n",
    "\n",
    "bids_path = BIDSPath(\n",
    "    root=parent_dir, subject=subj, session=sess, task=task, acquisition=acq, run=run, datatype=\"ieeg\"\n",
    ")\n",
    "print(bids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9faf41",
   "metadata": {},
   "source": [
    "## BIDS layout\n",
    "\n",
    "We can use `pybids` to show a little bit about the files in this BIDS dataset. We won't get as much into this, but if you'd like to try this tutorial on your own you may wish to delve into this more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953df68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d328249",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = layout.get()\n",
    "print(\"There are {} files in the layout.\".format(len(all_files)))\n",
    "print(\"\\nThe first 10 files are:\")\n",
    "all_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dir_tree(parent_dir, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da51ef",
   "metadata": {},
   "source": [
    "## Let's load some iEEG data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4431118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and extract parameters from BIDS files\n",
    "raw = read_raw_bids(bids_path, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f1ed8-2fd6-4688-bab3-29ce29da4ea6",
   "metadata": {},
   "source": [
    "## Plot the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5eb578-3e72-4190-86af-23034f7dd5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d69ff-14a0-4270-94f8-78615885d324",
   "metadata": {},
   "source": [
    "## Plot the power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b6b27-67b9-49c9-8499-406e60c86ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.compute_psd().plot(picks='data', exclude=[]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b55eb0",
   "metadata": {},
   "source": [
    "# Electrodes on the brain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f338cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "brain_kwargs = dict(alpha=0.1, background=\"white\", view='split',cortex=\"low_contrast\")\n",
    "brain = mne.viz.Brain(f'sub-{subj}', surf='pial', subjects_dir=f'{parent_dir}/freesurfer', alpha=0.5,\n",
    "                      background='white')\n",
    "trans = mne.read_trans(f'{parent_dir}/freesurfer/sub-{subj}/bem/sub-{subj}_head-trans.fif')\n",
    "brain.add_sensors(raw.info, trans=trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d3a3d-1120-489d-a183-335ee215709c",
   "metadata": {},
   "source": [
    "## Get the high gamma data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf559c1-36ac-4db4-a8a3-451a757b357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the iEEG channels for high gamma\n",
    "raw_ieeg = raw.copy()\n",
    "raw_ieeg.pick_types(seeg=True)\n",
    "raw_ieeg.anonymize()\n",
    "\n",
    "notch_freqs = list(np.arange(raw.info['line_freq'], raw.info['lowpass'], step=raw.info['line_freq']))\n",
    "# Get the high gamma data\n",
    "# Generally, do a CAR if you have widespread coverage over multiple\n",
    "# areas (not just one sensory area)\n",
    "# If you have limited coverage, you may choose to do no CAR or choose\n",
    "# to reference to one specific channel.\n",
    "ieeg_dir = f'{parent_dir}/sub-{subj}/ses-{sess}/ieeg/'\n",
    "hgdat = transformData(raw_ieeg, ieeg_dir, band='high_gamma', notch=True, CAR=True,\n",
    "                      car_chans='average', log_transform=True, do_zscore=True,\n",
    "                      hg_fs=100, notch_freqs=notch_freqs, ch_types='seeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fda05c-f32e-4a33-989b-cf74717b3592",
   "metadata": {},
   "source": [
    "## Get the events from BIDS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5833ca-e046-439b-b887-630bb96cda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.events_from_annotations(hgdat, event_id='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd51d4-1ae2-4d7c-80c1-05cc4812423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot the neural response for one electrode\n",
    "epochs = mne.Epochs(hgdat, events[0], tmin=-0.5, tmax=0.6)\n",
    "epochs.plot_image(picks=[hgdat.info['ch_names'][49]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498687b-0957-4b6b-a27b-ded4460f79fd",
   "metadata": {},
   "source": [
    "## We can use the function `epochs.get_data()` to get the values from our evoked data and normalize these values across channels. Then, create a dictionary of colors which represent which electrodes have the strongest responses to the onset of the speech sentences. We'll use this dictionary to plot these responses on the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9910be-c30b-4fcc-8073-752b1db6e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "edat=epochs.get_data().mean(0).mean(1)\n",
    "print(edat.shape)\n",
    "norm_edat = edat/edat.max()\n",
    "norm_edat[norm_edat<0]=0\n",
    "col = np.zeros((len(raw.info['ch_names']),3))\n",
    "col[:,0]=norm_edat\n",
    "colors = dict(seeg=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1348b-3074-4967-a935-2c904e820033",
   "metadata": {},
   "source": [
    "## Plot electrodes just colored by their average high gamma during sentence listening.\n",
    "\n",
    "The more red, the more speech-responsive the electrodes are in the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ebe28-3119-411d-b3d6-67aff34be192",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_kwargs = dict(alpha=0.1, background=\"white\", view='split',cortex=\"low_contrast\")\n",
    "brain = mne.viz.Brain(f'sub-{subj}', surf='pial', subjects_dir=f'{parent_dir}/freesurfer', alpha=0.5,\\\n",
    "                      background='white')\n",
    "trans = mne.read_trans(f'{parent_dir}/freesurfer/sub-{subj}/bem/sub-{subj}_head-trans.fif')\n",
    "brain.add_sensors(raw.info, trans=trans, sensor_colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49007a79-5f32-4a99-9d35-e4e84b258957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
